{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAyjmGReCiyjmg2bi3LTFc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lshmyrko/Challenge-5/blob/main/AlphabetSoupCharity_Optimization.h5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load the data\n",
        "url = \"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\"\n",
        "application_df = pd.read_csv(url)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "application_df = application_df.drop(columns=['EIN'])\n",
        "\n",
        "# Split data into features (X) and target (y)\n",
        "X = application_df.drop(\"IS_SUCCESSFUL\", axis=1)\n",
        "y = application_df[\"IS_SUCCESSFUL\"]\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
        "\n",
        "# Define preprocessing for numerical and categorical data\n",
        "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_features = X.select_dtypes(include=['object']).columns\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
        "])\n",
        "\n",
        "# Combine preprocessing steps\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Build the model with adjusted architecture\n",
        "model = Sequential()\n",
        "model.add(Dense(units=256, activation='relu', input_dim=preprocessor.fit_transform(X_train).shape[1]))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dense(units=16, activation='relu'))  # Additional hidden layer\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Use Adam optimizer with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "X_train_transformed = preprocessor.fit_transform(X_train)\n",
        "model.fit(X_train_transformed, y_train, epochs=40, batch_size=64, verbose=2)\n",
        "\n",
        "# Evaluate the model\n",
        "X_test_transformed = preprocessor.transform(X_test)\n",
        "model_loss, model_accuracy = model.evaluate(X_test_transformed, y_test, verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avZBT7gXnitU",
        "outputId": "12a9fd99-daab-4162-d850-fd78408ad87e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "402/402 - 28s - loss: 0.6150 - accuracy: 0.6869 - 28s/epoch - 70ms/step\n",
            "Epoch 2/40\n",
            "402/402 - 25s - loss: 0.4869 - accuracy: 0.7787 - 25s/epoch - 63ms/step\n",
            "Epoch 3/40\n",
            "402/402 - 25s - loss: 0.4214 - accuracy: 0.8111 - 25s/epoch - 62ms/step\n",
            "Epoch 4/40\n",
            "402/402 - 26s - loss: 0.3269 - accuracy: 0.8739 - 26s/epoch - 64ms/step\n",
            "Epoch 5/40\n",
            "402/402 - 26s - loss: 0.2136 - accuracy: 0.9339 - 26s/epoch - 64ms/step\n",
            "Epoch 6/40\n",
            "402/402 - 26s - loss: 0.1523 - accuracy: 0.9541 - 26s/epoch - 64ms/step\n",
            "Epoch 7/40\n",
            "402/402 - 26s - loss: 0.1278 - accuracy: 0.9598 - 26s/epoch - 64ms/step\n",
            "Epoch 8/40\n",
            "402/402 - 26s - loss: 0.1153 - accuracy: 0.9605 - 26s/epoch - 65ms/step\n",
            "Epoch 9/40\n",
            "402/402 - 26s - loss: 0.1078 - accuracy: 0.9618 - 26s/epoch - 64ms/step\n",
            "Epoch 10/40\n",
            "402/402 - 26s - loss: 0.1020 - accuracy: 0.9631 - 26s/epoch - 65ms/step\n",
            "Epoch 11/40\n",
            "402/402 - 26s - loss: 0.1015 - accuracy: 0.9632 - 26s/epoch - 64ms/step\n",
            "Epoch 12/40\n",
            "402/402 - 26s - loss: 0.0985 - accuracy: 0.9637 - 26s/epoch - 64ms/step\n",
            "Epoch 13/40\n",
            "402/402 - 26s - loss: 0.0961 - accuracy: 0.9648 - 26s/epoch - 64ms/step\n",
            "Epoch 14/40\n",
            "402/402 - 26s - loss: 0.0947 - accuracy: 0.9649 - 26s/epoch - 64ms/step\n",
            "Epoch 15/40\n",
            "402/402 - 26s - loss: 0.0939 - accuracy: 0.9644 - 26s/epoch - 64ms/step\n",
            "Epoch 16/40\n",
            "402/402 - 26s - loss: 0.0916 - accuracy: 0.9640 - 26s/epoch - 64ms/step\n",
            "Epoch 17/40\n",
            "402/402 - 26s - loss: 0.0941 - accuracy: 0.9645 - 26s/epoch - 64ms/step\n",
            "Epoch 18/40\n",
            "402/402 - 26s - loss: 0.0899 - accuracy: 0.9657 - 26s/epoch - 65ms/step\n",
            "Epoch 19/40\n",
            "402/402 - 26s - loss: 0.0904 - accuracy: 0.9659 - 26s/epoch - 64ms/step\n",
            "Epoch 20/40\n",
            "402/402 - 26s - loss: 0.0891 - accuracy: 0.9647 - 26s/epoch - 64ms/step\n",
            "Epoch 21/40\n",
            "402/402 - 26s - loss: 0.0882 - accuracy: 0.9661 - 26s/epoch - 64ms/step\n",
            "Epoch 22/40\n",
            "402/402 - 26s - loss: 0.0879 - accuracy: 0.9661 - 26s/epoch - 64ms/step\n",
            "Epoch 23/40\n",
            "402/402 - 26s - loss: 0.0866 - accuracy: 0.9666 - 26s/epoch - 64ms/step\n",
            "Epoch 24/40\n",
            "402/402 - 28s - loss: 0.0876 - accuracy: 0.9662 - 28s/epoch - 71ms/step\n",
            "Epoch 25/40\n",
            "402/402 - 25s - loss: 0.0872 - accuracy: 0.9658 - 25s/epoch - 63ms/step\n",
            "Epoch 26/40\n",
            "402/402 - 25s - loss: 0.0848 - accuracy: 0.9662 - 25s/epoch - 63ms/step\n",
            "Epoch 27/40\n",
            "402/402 - 26s - loss: 0.0854 - accuracy: 0.9662 - 26s/epoch - 64ms/step\n",
            "Epoch 28/40\n",
            "402/402 - 26s - loss: 0.0850 - accuracy: 0.9666 - 26s/epoch - 64ms/step\n",
            "Epoch 29/40\n",
            "402/402 - 26s - loss: 0.0849 - accuracy: 0.9665 - 26s/epoch - 64ms/step\n",
            "Epoch 30/40\n",
            "402/402 - 26s - loss: 0.0844 - accuracy: 0.9665 - 26s/epoch - 64ms/step\n",
            "Epoch 31/40\n",
            "402/402 - 25s - loss: 0.0840 - accuracy: 0.9668 - 25s/epoch - 63ms/step\n",
            "Epoch 32/40\n",
            "402/402 - 25s - loss: 0.0832 - accuracy: 0.9673 - 25s/epoch - 62ms/step\n",
            "Epoch 33/40\n",
            "402/402 - 26s - loss: 0.0845 - accuracy: 0.9661 - 26s/epoch - 64ms/step\n",
            "Epoch 34/40\n",
            "402/402 - 26s - loss: 0.0828 - accuracy: 0.9668 - 26s/epoch - 64ms/step\n",
            "Epoch 35/40\n",
            "402/402 - 25s - loss: 0.0822 - accuracy: 0.9680 - 25s/epoch - 63ms/step\n",
            "Epoch 36/40\n",
            "402/402 - 25s - loss: 0.0827 - accuracy: 0.9669 - 25s/epoch - 63ms/step\n",
            "Epoch 37/40\n",
            "402/402 - 25s - loss: 0.0819 - accuracy: 0.9682 - 25s/epoch - 63ms/step\n",
            "Epoch 38/40\n",
            "402/402 - 25s - loss: 0.0817 - accuracy: 0.9667 - 25s/epoch - 63ms/step\n",
            "Epoch 39/40\n",
            "402/402 - 26s - loss: 0.0810 - accuracy: 0.9679 - 26s/epoch - 64ms/step\n",
            "Epoch 40/40\n",
            "402/402 - 25s - loss: 0.0813 - accuracy: 0.9677 - 25s/epoch - 63ms/step\n",
            "268/268 - 3s - loss: 0.6684 - accuracy: 0.7345 - 3s/epoch - 11ms/step\n",
            "Loss: 0.6683646440505981, Accuracy: 0.7344606518745422\n"
          ]
        }
      ]
    }
  ]
}